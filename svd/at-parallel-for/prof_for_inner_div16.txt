after
1.8.0a0+4446145

batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)
[] 2 torch.float32                  0.024   0.222
[] 4 torch.float32                  0.029   0.379
[] 8 torch.float32                  0.036   0.448
[] 16 torch.float32                 0.063   0.517
[] 32 torch.float32                 0.322   0.623
[] 64 torch.float32                 0.867   1.221
[] 128 torch.float32                2.519   2.907
[] 256 torch.float32                9.425   8.107
[] 512 torch.float32                39.834   23.043
[] 1024 torch.float32               212.549   101.052
[1] 2 torch.float32                 0.064   0.208
[1] 4 torch.float32                 0.029   0.362
[1] 8 torch.float32                 0.034   0.424
[1] 16 torch.float32                0.063   0.513
[1] 32 torch.float32                0.319   0.629
[1] 64 torch.float32                0.837   1.224
[1] 128 torch.float32               2.518   2.925
[1] 256 torch.float32               9.694   8.165
[1] 512 torch.float32               40.511   23.184
[1] 1024 torch.float32              172.889   99.886
[2] 2 torch.float32                 0.067   0.097
[2] 4 torch.float32                 0.033   0.157
[2] 8 torch.float32                 0.049   0.194
[2] 16 torch.float32                0.106   0.266
[2] 32 torch.float32                0.553   0.344
[2] 64 torch.float32                1.519   2.064
[2] 128 torch.float32               4.383   4.409
[2] 256 torch.float32               18.119   12.396
[2] 512 torch.float32               81.819   41.368
[2] 1024 torch.float32              347.180   188.361
[4] 2 torch.float32                 0.036   0.106
[4] 4 torch.float32                 0.170   0.171
[4] 8 torch.float32                 0.086   0.205
[4] 16 torch.float32                0.222   0.278
[4] 32 torch.float32                1.397   0.356
[4] 64 torch.float32                3.081   5.807
[4] 128 torch.float32               11.435   11.528
[4] 256 torch.float32               36.348   25.948
[4] 512 torch.float32               162.816   58.336
[8] 2 torch.float32                 0.079   0.146
[8] 4 torch.float32                 0.141   0.166
[8] 8 torch.float32                 0.148   0.206
[8] 16 torch.float32                0.426   0.289
[8] 32 torch.float32                2.085   0.363
[8] 64 torch.float32                5.605   10.800
[8] 128 torch.float32               18.293   20.652
[8] 256 torch.float32               71.157   47.593
[16] 2 torch.float32                0.117   0.144
[16] 4 torch.float32                0.158   0.167
[16] 8 torch.float32                0.278   0.211
[16] 16 torch.float32               0.835   0.288
[16] 32 torch.float32               5.055   0.350
[16] 64 torch.float32               12.283   21.827
[16] 128 torch.float32              35.757   42.136
[32] 2 torch.float32                0.177   0.154
[32] 4 torch.float32                0.223   0.175
[32] 8 torch.float32                0.523   0.216
[32] 16 torch.float32               1.652   0.288
[32] 32 torch.float32               7.581   0.354
[32] 64 torch.float32               22.122   41.063
[64] 2 torch.float32                0.305   0.152
[64] 4 torch.float32                0.394   0.208
[64] 8 torch.float32                1.022   0.257
[64] 16 torch.float32               3.018   0.318
[64] 32 torch.float32               14.159   0.534
[128] 2 torch.float32               0.226   0.151
[128] 4 torch.float32               0.626   0.285
[128] 8 torch.float32               1.681   0.382
[128] 16 torch.float32              5.346   0.535
[256] 2 torch.float32               0.456   0.189
[256] 4 torch.float32               1.268   0.432
[256] 8 torch.float32               3.334   0.629
[512] 2 torch.float32               0.839   0.291
[512] 4 torch.float32               2.427   0.724
[1024] 2 torch.float32              1.650   0.498
