See pytorch PR https://github.com/pytorch/pytorch/pull/48436

before master commit 19f4c5110e8bcad5e7e75375194262fca0a6293a

after commit 72edde61d803fd917343c676b013805da2ab2b43

This page was tested on E5-2680 v3 and RTX 2070 Super. Libraries: intel-mkl 2020.2.254-1 and cuda 11.1

- before: magma
- after_1: gesvd
- after_2: gesvdj
- after_3: gesvdj + gesvdjBatched (when both dims <= 32)
- after_3x: after_3 + updated at::parallel_for (inner div 4, See ./at-parallel-for/sample-macro-code.cpp)

time is in **ms** (10^-3 s)

|shape|cpu|before|after_1|after_2|after_3|after_3x|
|---:|---:|---:|---:|---:|---:|---:|
| [] 2 torch.float32 |  0.026 |  1.624 |  0.206 |  0.215 |  0.255 |  0.254 |
| [] 4 torch.float32 |  0.029 |  1.381 |  0.299 |  0.312 |  0.359 |  0.358 |
| [] 8 torch.float32 |  0.037 |  1.364 |  0.453 |  0.452 |  0.502 |  0.500 |
| [] 16 torch.float32 |  0.065 |  1.429 |  0.778 |  0.464 |  0.614 |  0.547 |
| [] 32 torch.float32 |  0.345 |  2.244 |  1.493 |  0.613 |  0.661 |  0.655 |
| [] 64 torch.float32 |  0.818 |  2.268 |  3.543 |  1.205 |  1.262 |  1.314 |
| [] 128 torch.float32 |  2.401 |  8.966 |  8.623 |  2.940 |  2.959 |  3.087 |
| [] 256 torch.float32 |  9.370 |  28.048 |  25.734 |  7.912 |  8.040 |  7.969 |
| [] 512 torch.float32 |  41.001 |  71.162 |  102.131 |  22.941 |  23.547 |  23.398 |
| [] 1024 torch.float32 |  190.112 |  273.447 |  579.854 |  99.649 |  98.451 |  99.426 |
| [1] 2 torch.float32 |  0.038 |  1.942 |  0.231 |  0.201 |  0.204 |  0.206 |
| [1] 4 torch.float32 |  0.037 |  2.317 |  0.335 |  0.309 |  0.341 |  0.310 |
| [1] 8 torch.float32 |  0.045 |  2.272 |  0.507 |  0.411 |  0.422 |  0.367 |
| [1] 16 torch.float32 |  0.078 |  1.607 |  0.874 |  0.504 |  0.524 |  0.459 |
| [1] 32 torch.float32 |  0.304 |  2.372 |  1.632 |  0.611 |  0.573 |  0.626 |
| [1] 64 torch.float32 |  0.797 |  2.815 |  3.732 |  1.213 |  1.202 |  1.185 |
| [1] 128 torch.float32 |  2.379 |  9.200 |  9.064 |  2.901 |  2.915 |  2.923 |
| [1] 256 torch.float32 |  9.246 |  29.403 |  26.150 |  8.111 |  8.239 |  8.054 |
| [1] 512 torch.float32 |  40.218 |  75.919 |  102.661 |  23.375 |  23.989 |  23.809 |
| [1] 1024 torch.float32 |  173.433 |  242.375 |  582.987 |  98.094 |  99.713 |  100.132 |
| [2] 2 torch.float32 |  0.029 |  3.358 |  0.322 |  0.316 |  0.098 |  0.097 |
| [2] 4 torch.float32 |  0.041 |  2.935 |  0.497 |  0.531 |  0.156 |  0.139 |
| [2] 8 torch.float32 |  0.046 |  2.935 |  0.804 |  0.686 |  0.196 |  0.196 |
| [2] 16 torch.float32 |  0.103 |  3.027 |  1.472 |  0.935 |  0.270 |  0.271 |
| [2] 32 torch.float32 |  0.609 |  4.691 |  2.862 |  1.137 |  0.353 |  0.345 |
| [2] 64 torch.float32 |  1.675 |  5.471 |  6.917 |  2.325 |  2.355 |  2.282 |
| [2] 128 torch.float32 |  5.047 |  17.448 |  17.218 |  5.814 |  5.831 |  5.020 |
| [2] 256 torch.float32 |  18.267 |  54.771 |  50.414 |  15.998 |  16.267 |  12.779 |
| [2] 512 torch.float32 |  80.803 |  145.471 |  200.012 |  46.597 |  47.683 |  39.000 |
| [2] 1024 torch.float32 |  342.312 |  494.471 |  1162.145 |  196.642 |  195.095 |  180.718 |
| [4] 2 torch.float32 |  0.046 |  5.619 |  0.546 |  0.548 |  0.119 |  0.133 |
| [4] 4 torch.float32 |  0.047 |  5.669 |  0.939 |  1.030 |  0.178 |  0.163 |
| [4] 8 torch.float32 |  0.077 |  5.727 |  1.575 |  1.245 |  0.217 |  0.217 |
| [4] 16 torch.float32 |  0.197 |  5.936 |  2.873 |  1.769 |  0.308 |  0.291 |
| [4] 32 torch.float32 |  1.173 |  9.218 |  5.634 |  2.205 |  0.372 |  0.373 |
| [4] 64 torch.float32 |  3.107 |  9.099 |  13.716 |  4.545 |  4.822 |  4.433 |
| [4] 128 torch.float32 |  9.275 |  36.183 |  34.052 |  11.562 |  11.599 |  9.724 |
| [4] 256 torch.float32 |  35.770 |  114.162 |  100.016 |  32.560 |  32.481 |  24.481 |
| [4] 512 torch.float32 |  164.803 |  280.715 |  394.425 |  93.996 |  95.387 |  74.512 |
| [8] 2 torch.float32 |  0.049 |  11.721 |  1.036 |  0.988 |  0.102 |  0.128 |
| [8] 4 torch.float32 |  0.065 |  11.661 |  1.745 |  1.900 |  0.143 |  0.177 |
| [8] 8 torch.float32 |  0.128 |  11.655 |  3.071 |  2.628 |  0.229 |  0.217 |
| [8] 16 torch.float32 |  0.372 |  11.931 |  5.755 |  3.385 |  0.276 |  0.291 |
| [8] 32 torch.float32 |  1.992 |  15.173 |  11.331 |  4.233 |  0.356 |  0.368 |
| [8] 64 torch.float32 |  5.514 |  19.499 |  27.344 |  9.108 |  9.322 |  12.480 |
| [8] 128 torch.float32 |  17.891 |  70.354 |  67.321 |  23.154 |  23.425 |  23.160 |
| [8] 256 torch.float32 |  72.892 |  234.389 |  200.375 |  64.568 |  65.086 |  49.235 |
| [16] 2 torch.float32 |  0.062 |  22.706 |  1.945 |  1.884 |  0.101 |  0.133 |
| [16] 4 torch.float32 |  0.103 |  22.740 |  3.349 |  3.793 |  0.160 |  0.170 |
| [16] 8 torch.float32 |  0.233 |  22.971 |  5.863 |  5.057 |  0.201 |  0.211 |
| [16] 16 torch.float32 |  0.720 |  23.412 |  11.126 |  6.664 |  0.281 |  0.292 |
| [16] 32 torch.float32 |  3.871 |  29.633 |  22.174 |  8.225 |  0.355 |  0.366 |
| [16] 64 torch.float32 |  11.189 |  40.003 |  53.875 |  17.867 |  18.709 |  21.845 |
| [16] 128 torch.float32 |  36.502 |  138.227 |  134.162 |  45.664 |  46.196 |  46.719 |
| [32] 2 torch.float32 |  0.096 |  45.338 |  3.819 |  3.669 |  0.118 |  0.159 |
| [32] 4 torch.float32 |  0.185 |  45.438 |  6.822 |  7.309 |  0.160 |  0.181 |
| [32] 8 torch.float32 |  0.450 |  47.594 |  11.824 |  10.198 |  0.201 |  0.218 |
| [32] 16 torch.float32 |  1.413 |  48.721 |  22.410 |  13.252 |  0.283 |  0.295 |
| [32] 32 torch.float32 |  7.370 |  61.844 |  44.549 |  16.419 |  0.364 |  0.355 |
| [32] 64 torch.float32 |  22.072 |  78.596 |  107.863 |  35.681 |  37.525 |  36.802 |
| [64] 2 torch.float32 |  0.158 |  92.296 |  7.515 |  7.292 |  0.127 |  0.128 |
| [64] 4 torch.float32 |  0.344 |  91.349 |  13.519 |  14.703 |  0.201 |  0.218 |
| [64] 8 torch.float32 |  0.884 |  93.665 |  23.592 |  20.017 |  0.250 |  0.267 |
| [64] 16 torch.float32 |  2.799 |  95.347 |  44.793 |  26.501 |  0.325 |  0.341 |
| [64] 32 torch.float32 |  16.014 |  122.030 |  89.137 |  33.202 |  0.536 |  0.531 |
| [128] 2 torch.float32 |  0.231 |  186.144 |  15.096 |  14.582 |  0.151 |  0.151 |
| [128] 4 torch.float32 |  0.631 |  186.209 |  26.771 |  29.967 |  0.286 |  0.300 |
| [128] 8 torch.float32 |  1.654 |  184.716 |  47.386 |  39.732 |  0.390 |  0.405 |
| [128] 16 torch.float32 |  5.304 |  191.366 |  89.578 |  52.256 |  0.542 |  0.568 |
| [256] 2 torch.float32 |  0.441 |  361.648 |  29.828 |  28.889 |  0.195 |  0.190 |
| [256] 4 torch.float32 |  1.240 |  371.878 |  53.513 |  59.414 |  0.423 |  0.433 |
| [256] 8 torch.float32 |  3.298 |  365.996 |  94.705 |  79.853 |  0.632 |  0.635 |
| [512] 2 torch.float32 |  0.855 |  737.991 |  59.543 |  57.562 |  0.301 |  0.299 |
| [512] 4 torch.float32 |  2.455 |  738.817 |  106.619 |  118.540 |  0.730 |  0.727 |
| [1024] 2 torch.float32 |  1.699 |  1475.765 |  119.638 |  115.037 |  0.491 |  0.481 |
