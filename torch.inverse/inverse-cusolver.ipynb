{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce RTX 2070 SUPER \r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L | cut -d '(' -f 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "nb = 500\n",
    "\n",
    "def main(s: str):\n",
    "    def prof(b_, n_, dtype, f):\n",
    "        # print(b_, n_)\n",
    "        x = torch.randn(*b_, n_, n_, device='cuda', dtype=dtype)\n",
    "\n",
    "        xc = x.clone().cpu()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            yc = torch.inverse(xc)\n",
    "        t2 = time.time()\n",
    "        cpu_time = (t2-t1)/nb*1e3\n",
    "        # print('cpu', cpu_time, 'ms')\n",
    "\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        c, d = torch.testing._compare_tensors_internal(xc.cuda(), x, rtol=1e-7, atol=1e-7, equal_nan=False)\n",
    "        if not c:\n",
    "            print('original matrix compare')\n",
    "            print(d)\n",
    "            raise RuntimeError('original value modified')\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.time()\n",
    "        gpu_time = (t2-t1)/nb*1e3\n",
    "        # print('gpu', gpu_time, 'ms')\n",
    "\n",
    "        a, b = torch.testing._compare_tensors_internal(yc.cuda(), y, rtol=1e-3, atol=1e-3, equal_nan=False)\n",
    "        if not a:\n",
    "            print('numerical mismatch: inverse value compare')\n",
    "            print(b)\n",
    "\n",
    "        print(f'{b_} {n_} {dtype}'.ljust(35) + f'{cpu_time : .3f}  {gpu_time : .3f}')\n",
    "        f.write(f'{b_} {n_} {dtype}; ' + f'{cpu_time : .3e}, {gpu_time : .3e}\\n')\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    print(s)\n",
    "    print(torch.__version__)\n",
    "    print()\n",
    "    print('batch_size, matrix_size, dtype'.ljust(35) + 'cpu_time(ms), gpu_time(ms)')\n",
    "    \n",
    "    shapes = itertools.product(\n",
    "        [[]] + [[2**x] for x in range(3)],\n",
    "        [2**i for i in range(1, 11)],\n",
    "        [torch.float]\n",
    "    )\n",
    "\n",
    "    with open(s+'.txt', 'w') as f:\n",
    "        for b, n, dtype in shapes:\n",
    "            if len(b) > 0 and b[0] * n >= 2**15:\n",
    "                continue\n",
    "            prof(b, n, dtype, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "1.7.0a0+71510c6\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.121   7.318\n",
      "[] 4 torch.float32                  0.009   7.370\n",
      "[] 8 torch.float32                  0.011   7.376\n",
      "[] 16 torch.float32                 0.039   7.359\n",
      "[] 32 torch.float32                 0.102   7.437\n",
      "[] 64 torch.float32                 0.148   7.568\n",
      "[] 128 torch.float32                0.467   7.896\n",
      "[] 256 torch.float32                1.135   11.618\n",
      "[] 512 torch.float32                5.214   14.835\n",
      "[] 1024 torch.float32               19.311   18.583\n",
      "[1] 2 torch.float32                 0.009   0.110\n",
      "[1] 4 torch.float32                 0.009   0.113\n",
      "[1] 8 torch.float32                 0.010   0.113\n",
      "[1] 16 torch.float32                0.015   0.119\n",
      "[1] 32 torch.float32                0.031   0.196\n",
      "[1] 64 torch.float32                0.068   0.422\n",
      "[1] 128 torch.float32               0.330   0.803\n",
      "[1] 256 torch.float32               1.072   1.684\n",
      "[1] 512 torch.float32               4.796   4.262\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 145994 element(s) (out of 1048576) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.01626729965209961 (7.643503189086914 vs. 7.659770488739014), which occurred at index (0, 272, 758).\n",
      "[1] 1024 torch.float32              16.589   16.351\n",
      "[2] 2 torch.float32                 0.009   0.111\n",
      "[2] 4 torch.float32                 0.010   0.114\n",
      "[2] 8 torch.float32                 0.012   0.115\n",
      "[2] 16 torch.float32                0.020   0.119\n",
      "[2] 32 torch.float32                0.049   0.170\n",
      "[2] 64 torch.float32                0.119   0.430\n",
      "[2] 128 torch.float32               0.565   0.909\n",
      "[2] 256 torch.float32               2.072   1.854\n",
      "[2] 512 torch.float32               9.063   4.579\n",
      "[2] 1024 torch.float32              32.104   18.423\n",
      "[4] 2 torch.float32                 0.009   0.111\n",
      "[4] 4 torch.float32                 0.011   0.114\n",
      "[4] 8 torch.float32                 0.013   0.116\n",
      "[4] 16 torch.float32                0.027   0.120\n",
      "[4] 32 torch.float32                0.083   0.174\n",
      "[4] 64 torch.float32                0.219   0.439\n",
      "[4] 128 torch.float32               0.997   0.860\n",
      "[4] 256 torch.float32               4.092   1.846\n",
      "[4] 512 torch.float32               18.764   5.138\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 302956 element(s) (out of 4194304) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.02138662338256836 (-6.093076229095459 vs. -6.071689605712891), which occurred at index (2, 201, 940).\n",
      "[4] 1024 torch.float32              69.155   20.065\n"
     ]
    }
   ],
   "source": [
    "main('before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n",
      "1.7.0a0+1e36b48\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.010   0.162\n",
      "[] 4 torch.float32                  0.013   0.160\n",
      "[] 8 torch.float32                  0.014   0.161\n",
      "[] 16 torch.float32                 0.017   0.135\n",
      "[] 32 torch.float32                 0.034   0.187\n",
      "[] 64 torch.float32                 0.073   0.270\n",
      "[] 128 torch.float32                0.359   0.488\n",
      "[] 256 torch.float32                1.099   1.082\n",
      "[] 512 torch.float32                5.103   2.582\n",
      "[] 1024 torch.float32               17.298   7.057\n",
      "[1] 2 torch.float32                 0.010   0.161\n",
      "[1] 4 torch.float32                 0.010   0.170\n",
      "[1] 8 torch.float32                 0.014   0.143\n",
      "[1] 16 torch.float32                0.016   0.139\n",
      "[1] 32 torch.float32                0.033   0.177\n",
      "[1] 64 torch.float32                0.072   0.272\n",
      "[1] 128 torch.float32               0.281   0.500\n",
      "[1] 256 torch.float32               1.123   1.078\n",
      "[1] 512 torch.float32               4.498   2.605\n",
      "[1] 1024 torch.float32              16.697   6.934\n",
      "[2] 2 torch.float32                 0.010   0.191\n",
      "[2] 4 torch.float32                 0.011   0.182\n",
      "[2] 8 torch.float32                 0.012   0.183\n",
      "[2] 16 torch.float32                0.020   0.172\n",
      "[2] 32 torch.float32                0.052   0.241\n",
      "[2] 64 torch.float32                0.121   0.366\n",
      "[2] 128 torch.float32               0.670   0.672\n",
      "[2] 256 torch.float32               2.018   1.451\n",
      "[2] 512 torch.float32               8.679   3.543\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 1022930 element(s) (out of 2097152) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.3483657836914062 (-81.44357299804688 vs. -82.79193878173828), which occurred at index (0, 768, 194).\n",
      "[2] 1024 torch.float32              36.029   12.158\n",
      "[4] 2 torch.float32                 0.010   0.328\n",
      "[4] 4 torch.float32                 0.010   0.327\n",
      "[4] 8 torch.float32                 0.014   0.329\n",
      "[4] 16 torch.float32                0.028   0.337\n",
      "[4] 32 torch.float32                0.086   0.393\n",
      "[4] 64 torch.float32                0.224   0.649\n",
      "[4] 128 torch.float32               1.169   1.219\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 65283 element(s) (out of 262144) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 5.40093994140625 (-351.71075439453125 vs. -346.309814453125), which occurred at index (3, 64, 147).\n",
      "[4] 256 torch.float32               4.132   2.016\n",
      "[4] 512 torch.float32               18.597   5.079\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 1018089 element(s) (out of 4194304) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 1.302490234375 (44.74304962158203 vs. 43.44055938720703), which occurred at index (3, 663, 743).\n",
      "[4] 1024 torch.float32              69.349   19.971\n"
     ]
    }
   ],
   "source": [
    "main('after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape                      cpu_time, gpu_time_before (magma), gpu_time_after\n",
      "[] 2 torch.float32          0.066,  7.318,  0.162,      \n",
      "[] 4 torch.float32          0.011,  7.370,  0.160,      \n",
      "[] 8 torch.float32          0.012,  7.376,  0.161,      \n",
      "[] 16 torch.float32         0.028,  7.359,  0.135,      \n",
      "[] 32 torch.float32         0.068,  7.437,  0.187,      \n",
      "[] 64 torch.float32         0.111,  7.568,  0.270,      \n",
      "[] 128 torch.float32        0.413,  7.896,  0.488,      \n",
      "[] 256 torch.float32        1.117,  11.620,  1.082,      \n",
      "[] 512 torch.float32        5.159,  14.830,  2.582,      \n",
      "[] 1024 torch.float32       18.305,  18.580,  7.057,      \n",
      "[1] 2 torch.float32         0.009,  0.110,  0.161,           ******************** regressed\n",
      "[1] 4 torch.float32         0.009,  0.113,  0.170,           ******************** regressed\n",
      "[1] 8 torch.float32         0.012,  0.113,  0.143,           ******************** regressed\n",
      "[1] 16 torch.float32        0.016,  0.119,  0.139,           ******************** regressed\n",
      "[1] 32 torch.float32        0.032,  0.196,  0.177,      \n",
      "[1] 64 torch.float32        0.070,  0.422,  0.272,      \n",
      "[1] 128 torch.float32       0.306,  0.803,  0.500,      \n",
      "[1] 256 torch.float32       1.098,  1.684,  1.078,      \n",
      "[1] 512 torch.float32       4.647,  4.262,  2.605,      \n",
      "[1] 1024 torch.float32      16.645,  16.350,  6.934,      \n",
      "[2] 2 torch.float32         0.009,  0.111,  0.191,           ******************** regressed\n",
      "[2] 4 torch.float32         0.010,  0.114,  0.182,           ******************** regressed\n",
      "[2] 8 torch.float32         0.012,  0.115,  0.183,           ******************** regressed\n",
      "[2] 16 torch.float32        0.020,  0.119,  0.172,           ******************** regressed\n",
      "[2] 32 torch.float32        0.051,  0.170,  0.241,           ******************** regressed\n",
      "[2] 64 torch.float32        0.120,  0.430,  0.366,      \n",
      "[2] 128 torch.float32       0.618,  0.909,  0.672,      \n",
      "[2] 256 torch.float32       2.045,  1.854,  1.451,      \n",
      "[2] 512 torch.float32       8.871,  4.579,  3.543,      \n",
      "[2] 1024 torch.float32      34.065,  18.420,  12.160,      \n",
      "[4] 2 torch.float32         0.010,  0.111,  0.328,           ******************** regressed\n",
      "[4] 4 torch.float32         0.010,  0.114,  0.327,           ******************** regressed\n",
      "[4] 8 torch.float32         0.014,  0.116,  0.329,           ******************** regressed\n",
      "[4] 16 torch.float32        0.027,  0.120,  0.337,           ******************** regressed\n",
      "[4] 32 torch.float32        0.085,  0.174,  0.393,           ******************** regressed\n",
      "[4] 64 torch.float32        0.221,  0.439,  0.649,           ******************** regressed\n",
      "[4] 128 torch.float32       1.083,  0.860,  1.219,           ******************** regressed\n",
      "[4] 256 torch.float32       4.112,  1.846,  2.016,           ******************** regressed\n",
      "[4] 512 torch.float32       18.680,  5.138,  5.079,      \n",
      "[4] 1024 torch.float32      69.250,  20.070,  19.970,      \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def readfile(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        fl = f.readlines()\n",
    "    \n",
    "    dc = {}\n",
    "    dg = {}\n",
    "    for _line in fl:\n",
    "        key, cpu_time, gpu_time = re.split(';|,', _line.rstrip())\n",
    "        dc[key] = float(cpu_time)\n",
    "        dg[key] = float(gpu_time)\n",
    "    \n",
    "    return (dc, dg)\n",
    "\n",
    "def compare(f, before: str, *afters):\n",
    "    assert len(afters) >= 1, 'provide at least one after data'\n",
    "\n",
    "    print('shape'.ljust(26), 'cpu_time, gpu_time_before (magma)', end='')\n",
    "    f.write('| shape | cpu_time (ms) | gpu_time_before (magma) (ms) |')\n",
    "    for after in afters:\n",
    "        print(', gpu_time_' + after.rstrip('.txt'), end='')\n",
    "        f.write(' gpu_time_' + after.rstrip('.txt') + ' (ms) |')\n",
    "    print()\n",
    "    f.write('\\n')\n",
    "    f.write('| --- ' * (len(afters) + 3) + '| \\n')\n",
    "\n",
    "    dc_b, dg_b = readfile(before)\n",
    "    dc_as = []\n",
    "    dg_as = []\n",
    "    for after in afters:\n",
    "        dc_a, dg_a = readfile(after)\n",
    "        dc_as.append(dc_a)\n",
    "        dg_as.append(dg_a)\n",
    "    \n",
    "    for key in dc_b:\n",
    "        cpu_time = (dc_b[key] + sum(dc_a[key] for dc_a in dc_as)) / (1 + len(dc_as))\n",
    "        gpu_time_before = dg_b[key]\n",
    "        gpu_time_after = dg_as[0][key]\n",
    "        \n",
    "        if gpu_time_after > gpu_time_before:\n",
    "            gs = ' ' * 5 + '*' * 20 + ' regressed'\n",
    "            gss = '***regressed'\n",
    "        else:\n",
    "            gs = ''\n",
    "            gss = ''\n",
    "\n",
    "        print(f'{key: <26} {cpu_time: .3f}, {gpu_time_before: .3f}, {gpu_time_after: .3f}, ' + ' '*5, end='')\n",
    "        f.write(f'| {key} | {cpu_time: .3f} | {gpu_time_before: .3f} | {gpu_time_after: .3f} {gss} | ')\n",
    "        for dg_a in dg_as[1:]:\n",
    "            gpu_time_after = dg_a[key]\n",
    "            print(f'{gpu_time_after: .3f}, ', end='')\n",
    "            f.write(f'{gpu_time_after: .3f} |')\n",
    "        print(gs)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('table.md', 'w') as f:\n",
    "    compare(f, 'before.txt', 'after.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitfce950e88ea94256bae6c6f663f53e68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
