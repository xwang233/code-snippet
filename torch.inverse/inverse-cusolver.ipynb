{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce RTX 2070 SUPER \r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L | cut -d '(' -f 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "nb = 500\n",
    "\n",
    "def main(s: str):\n",
    "    def prof(b_, n_, dtype, f):\n",
    "        # print(b_, n_)\n",
    "        x = torch.randn(*b_, n_, n_, device='cuda', dtype=dtype)\n",
    "\n",
    "        xc = x.clone().cpu()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            yc = torch.inverse(xc)\n",
    "        t2 = time.time()\n",
    "        cpu_time = (t2-t1)/nb*1e3\n",
    "        # print('cpu', cpu_time, 'ms')\n",
    "\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        c, d = torch.testing._compare_tensors_internal(xc.cuda(), x, rtol=1e-7, atol=1e-7, equal_nan=False)\n",
    "        if not c:\n",
    "            print('original matrix compare')\n",
    "            print(d)\n",
    "            raise RuntimeError('original value modified')\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.time()\n",
    "        gpu_time = (t2-t1)/nb*1e3\n",
    "        # print('gpu', gpu_time, 'ms')\n",
    "\n",
    "        a, b = torch.testing._compare_tensors_internal(yc.cuda(), y, rtol=1e-3, atol=1e-3, equal_nan=False)\n",
    "        if not a:\n",
    "            print('numerical mismatch: inverse value compare')\n",
    "            print(b)\n",
    "\n",
    "        print(f'{b_} {n_} {dtype}'.ljust(35) + f'{cpu_time : .3f}  {gpu_time : .3f}')\n",
    "        f.write(f'{b_} {n_} {dtype}; ' + f'{cpu_time : .3e}, {gpu_time : .3e}\\n')\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    print(s)\n",
    "    print(torch.__version__)\n",
    "    print()\n",
    "    print('batch_size, matrix_size, dtype'.ljust(35) + 'cpu_time(ms), gpu_time(ms)')\n",
    "    \n",
    "    shapes = itertools.product(\n",
    "        [[]] + [[2**x] for x in range(3)],\n",
    "        [2**i for i in range(1, 11)],\n",
    "        [torch.float]\n",
    "    )\n",
    "\n",
    "    with open(s+'.txt', 'w') as f:\n",
    "        for b, n, dtype in shapes:\n",
    "            if len(b) > 0 and b[0] * n >= 2**15:\n",
    "                continue\n",
    "            prof(b, n, dtype, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "1.7.0a0+4ae832e\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.011   7.446\n",
      "[] 4 torch.float32                  0.009   7.427\n",
      "[] 8 torch.float32                  0.011   7.571\n",
      "[] 16 torch.float32                 0.016   7.522\n",
      "[] 32 torch.float32                 0.033   7.548\n",
      "[] 64 torch.float32                 0.072   7.708\n",
      "[] 128 torch.float32                0.352   8.024\n",
      "[] 256 torch.float32                1.141   11.338\n",
      "[] 512 torch.float32                5.312   15.013\n",
      "[] 1024 torch.float32               19.364   19.271\n",
      "[1] 2 torch.float32                 0.009   0.114\n",
      "[1] 4 torch.float32                 0.009   0.117\n",
      "[1] 8 torch.float32                 0.011   0.126\n",
      "[1] 16 torch.float32                0.017   0.127\n",
      "[1] 32 torch.float32                0.033   0.178\n",
      "[1] 64 torch.float32                0.072   0.420\n",
      "[1] 128 torch.float32               0.294   0.801\n",
      "[1] 256 torch.float32               1.044   1.674\n",
      "[1] 512 torch.float32               4.726   4.791\n",
      "[1] 1024 torch.float32              16.592   16.266\n",
      "[2] 2 torch.float32                 0.010   0.114\n",
      "[2] 4 torch.float32                 0.010   0.120\n",
      "[2] 8 torch.float32                 0.013   0.119\n",
      "[2] 16 torch.float32                0.020   0.129\n",
      "[2] 32 torch.float32                0.050   0.174\n",
      "[2] 64 torch.float32                0.122   0.427\n",
      "[2] 128 torch.float32               0.553   0.914\n",
      "[2] 256 torch.float32               2.067   1.799\n",
      "[2] 512 torch.float32               9.127   4.506\n",
      "[2] 1024 torch.float32              32.653   18.171\n",
      "[4] 2 torch.float32                 0.010   0.115\n",
      "[4] 4 torch.float32                 0.010   0.118\n",
      "[4] 8 torch.float32                 0.014   0.118\n",
      "[4] 16 torch.float32                0.028   0.122\n",
      "[4] 32 torch.float32                0.086   0.175\n",
      "[4] 64 torch.float32                0.228   0.431\n",
      "[4] 128 torch.float32               1.065   0.932\n",
      "[4] 256 torch.float32               4.001   1.808\n",
      "[4] 512 torch.float32               18.434   4.896\n",
      "[4] 1024 torch.float32              59.073   19.991\n"
     ]
    }
   ],
   "source": [
    "main('before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n",
      "1.7.0a0+060769f\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.010   0.117\n",
      "[] 4 torch.float32                  0.010   0.125\n",
      "[] 8 torch.float32                  0.011   0.127\n",
      "[] 16 torch.float32                 0.016   0.125\n",
      "[] 32 torch.float32                 0.033   0.173\n",
      "[] 64 torch.float32                 0.072   0.270\n",
      "[] 128 torch.float32                0.352   0.481\n",
      "[] 256 torch.float32                1.072   1.081\n",
      "[] 512 torch.float32                4.658   2.581\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 930855 element(s) (out of 1048576) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.4300537109375 (-46.73646926879883 vs. -46.30641555786133), which occurred at index (948, 117).\n",
      "[] 1024 torch.float32               19.422   6.952\n",
      "[1] 2 torch.float32                 0.009   0.134\n",
      "[1] 4 torch.float32                 0.009   0.133\n",
      "[1] 8 torch.float32                 0.011   0.132\n",
      "[1] 16 torch.float32                0.015   0.130\n",
      "[1] 32 torch.float32                0.032   0.174\n",
      "[1] 64 torch.float32                0.069   0.268\n",
      "[1] 128 torch.float32               0.341   0.503\n",
      "[1] 256 torch.float32               1.073   1.080\n",
      "[1] 512 torch.float32               4.658   2.585\n",
      "[1] 1024 torch.float32              16.606   6.948\n",
      "[2] 2 torch.float32                 0.009   0.189\n",
      "[2] 4 torch.float32                 0.009   0.184\n",
      "[2] 8 torch.float32                 0.012   0.184\n",
      "[2] 16 torch.float32                0.019   0.176\n",
      "[2] 32 torch.float32                0.051   0.245\n",
      "[2] 64 torch.float32                0.119   0.376\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 15935 element(s) (out of 32768) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 2.772216796875 (575.23095703125 vs. 572.458740234375), which occurred at index (1, 121, 32).\n",
      "[2] 128 torch.float32               0.752   0.729\n",
      "[2] 256 torch.float32               2.237   1.477\n",
      "[2] 512 torch.float32               9.589   3.555\n",
      "[2] 1024 torch.float32              33.165   12.332\n",
      "[4] 2 torch.float32                 0.010   0.324\n",
      "[4] 4 torch.float32                 0.010   0.324\n",
      "[4] 8 torch.float32                 0.013   0.324\n",
      "[4] 16 torch.float32                0.027   0.333\n",
      "[4] 32 torch.float32                0.090   0.392\n",
      "[4] 64 torch.float32                0.222   0.650\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 16359 element(s) (out of 65536) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 13.3687744140625 (1134.3485107421875 vs. 1120.979736328125), which occurred at index (0, 57, 59).\n",
      "[4] 128 torch.float32               1.215   1.048\n",
      "[4] 256 torch.float32               4.305   2.034\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 74714 element(s) (out of 1048576) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.043506622314453125 (30.7841796875 vs. 30.827686309814453), which occurred at index (3, 130, 406).\n",
      "[4] 512 torch.float32               18.128   5.069\n",
      "[4] 1024 torch.float32              66.882   19.704\n"
     ]
    }
   ],
   "source": [
    "main('after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape                      cpu_time, gpu_time_before (magma), gpu_time_after\n",
      "[] 2 torch.float32          0.010,  7.446,  0.117,      \n",
      "[] 4 torch.float32          0.010,  7.427,  0.125,      \n",
      "[] 8 torch.float32          0.011,  7.571,  0.127,      \n",
      "[] 16 torch.float32         0.016,  7.522,  0.125,      \n",
      "[] 32 torch.float32         0.033,  7.548,  0.173,      \n",
      "[] 64 torch.float32         0.072,  7.708,  0.270,      \n",
      "[] 128 torch.float32        0.352,  8.024,  0.481,      \n",
      "[] 256 torch.float32        1.107,  11.340,  1.081,      \n",
      "[] 512 torch.float32        4.985,  15.010,  2.581,      \n",
      "[] 1024 torch.float32       19.390,  19.270,  6.952,      \n",
      "[1] 2 torch.float32         0.009,  0.114,  0.134,           ******************** regressed\n",
      "[1] 4 torch.float32         0.009,  0.117,  0.133,           ******************** regressed\n",
      "[1] 8 torch.float32         0.011,  0.126,  0.132,           ******************** regressed\n",
      "[1] 16 torch.float32        0.016,  0.127,  0.130,           ******************** regressed\n",
      "[1] 32 torch.float32        0.032,  0.178,  0.174,      \n",
      "[1] 64 torch.float32        0.070,  0.420,  0.268,      \n",
      "[1] 128 torch.float32       0.318,  0.801,  0.503,      \n",
      "[1] 256 torch.float32       1.058,  1.674,  1.080,      \n",
      "[1] 512 torch.float32       4.692,  4.791,  2.585,      \n",
      "[1] 1024 torch.float32      16.600,  16.270,  6.948,      \n",
      "[2] 2 torch.float32         0.010,  0.114,  0.189,           ******************** regressed\n",
      "[2] 4 torch.float32         0.010,  0.120,  0.184,           ******************** regressed\n",
      "[2] 8 torch.float32         0.012,  0.118,  0.184,           ******************** regressed\n",
      "[2] 16 torch.float32        0.020,  0.129,  0.176,           ******************** regressed\n",
      "[2] 32 torch.float32        0.051,  0.173,  0.245,           ******************** regressed\n",
      "[2] 64 torch.float32        0.120,  0.427,  0.376,      \n",
      "[2] 128 torch.float32       0.653,  0.914,  0.729,      \n",
      "[2] 256 torch.float32       2.152,  1.799,  1.477,      \n",
      "[2] 512 torch.float32       9.358,  4.506,  3.555,      \n",
      "[2] 1024 torch.float32      32.910,  18.170,  12.330,      \n",
      "[4] 2 torch.float32         0.010,  0.115,  0.324,           ******************** regressed\n",
      "[4] 4 torch.float32         0.010,  0.118,  0.324,           ******************** regressed\n",
      "[4] 8 torch.float32         0.014,  0.118,  0.324,           ******************** regressed\n",
      "[4] 16 torch.float32        0.028,  0.122,  0.333,           ******************** regressed\n",
      "[4] 32 torch.float32        0.088,  0.175,  0.392,           ******************** regressed\n",
      "[4] 64 torch.float32        0.225,  0.431,  0.650,           ******************** regressed\n",
      "[4] 128 torch.float32       1.140,  0.932,  1.048,           ******************** regressed\n",
      "[4] 256 torch.float32       4.153,  1.808,  2.034,           ******************** regressed\n",
      "[4] 512 torch.float32       18.280,  4.896,  5.069,           ******************** regressed\n",
      "[4] 1024 torch.float32      62.975,  19.990,  19.700,      \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def readfile(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        fl = f.readlines()\n",
    "    \n",
    "    dc = {}\n",
    "    dg = {}\n",
    "    for _line in fl:\n",
    "        key, cpu_time, gpu_time = re.split(';|,', _line.rstrip())\n",
    "        dc[key] = float(cpu_time)\n",
    "        dg[key] = float(gpu_time)\n",
    "    \n",
    "    return (dc, dg)\n",
    "\n",
    "def compare(f, before: str, *afters):\n",
    "    assert len(afters) >= 1, 'provide at least one after data'\n",
    "\n",
    "    print('shape'.ljust(26), 'cpu_time, gpu_time_before (magma)', end='')\n",
    "    f.write('| shape | cpu_time (ms) | gpu_time_before (magma) (ms) |')\n",
    "    for after in afters:\n",
    "        print(', gpu_time_' + after.rstrip('.txt'), end='')\n",
    "        f.write(' gpu_time_' + after.rstrip('.txt') + ' (ms) |')\n",
    "    print()\n",
    "    f.write('\\n')\n",
    "    f.write('| --- ' * (len(afters) + 3) + '| \\n')\n",
    "\n",
    "    dc_b, dg_b = readfile(before)\n",
    "    dc_as = []\n",
    "    dg_as = []\n",
    "    for after in afters:\n",
    "        dc_a, dg_a = readfile(after)\n",
    "        dc_as.append(dc_a)\n",
    "        dg_as.append(dg_a)\n",
    "    \n",
    "    for key in dc_b:\n",
    "        cpu_time = (dc_b[key] + sum(dc_a[key] for dc_a in dc_as)) / (1 + len(dc_as))\n",
    "        gpu_time_before = dg_b[key]\n",
    "        gpu_time_after = dg_as[0][key]\n",
    "        \n",
    "        if gpu_time_after > gpu_time_before:\n",
    "            gs = ' ' * 5 + '*' * 20 + ' regressed'\n",
    "            gss = '***regressed'\n",
    "        else:\n",
    "            gs = ''\n",
    "            gss = ''\n",
    "\n",
    "        print(f'{key: <26} {cpu_time: .3f}, {gpu_time_before: .3f}, {gpu_time_after: .3f}, ' + ' '*5, end='')\n",
    "        f.write(f'| {key} | {cpu_time: .3f} | {gpu_time_before: .3f} | {gpu_time_after: .3f} {gss} | ')\n",
    "        for dg_a in dg_as[1:]:\n",
    "            gpu_time_after = dg_a[key]\n",
    "            print(f'{gpu_time_after: .3f}, ', end='')\n",
    "            f.write(f'{gpu_time_after: .3f} |')\n",
    "        print(gs)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('table.md', 'w') as f:\n",
    "    compare(f, 'before.txt', 'after.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitfce950e88ea94256bae6c6f663f53e68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
