{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce RTX 2070 SUPER \r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L | cut -d '(' -f 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "nb = 500\n",
    "\n",
    "def main(s: str):\n",
    "    def prof(b_, n_, dtype, f):\n",
    "        # print(b_, n_)\n",
    "        x = torch.randn(*b_, n_, n_, device='cuda', dtype=dtype)\n",
    "\n",
    "        xc = x.clone().cpu()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            yc = torch.inverse(xc)\n",
    "        t2 = time.time()\n",
    "        cpu_time = (t2-t1)/nb*1e3\n",
    "        # print('cpu', cpu_time, 'ms')\n",
    "\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        c, d = torch.testing._compare_tensors_internal(xc.cuda(), x, rtol=1e-7, atol=1e-7, equal_nan=False)\n",
    "        if not c:\n",
    "            print('original matrix compare')\n",
    "            print(d)\n",
    "            raise RuntimeError('original value modified')\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.time()\n",
    "        gpu_time = (t2-t1)/nb*1e3\n",
    "        # print('gpu', gpu_time, 'ms')\n",
    "\n",
    "        a, b = torch.testing._compare_tensors_internal(yc.cuda(), y, rtol=1e-3, atol=1e-3, equal_nan=False)\n",
    "        if not a:\n",
    "            print('numerical mismatch: inverse value compare')\n",
    "            print(b)\n",
    "\n",
    "        print(f'{b_} {n_} {dtype}'.ljust(35) + f'{cpu_time : .3f}  {gpu_time : .3f}')\n",
    "        f.write(f'{b_} {n_} {dtype}; ' + f'{cpu_time : .3e}, {gpu_time : .3e}\\n')\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    print(s)\n",
    "    print(torch.__version__)\n",
    "    print()\n",
    "    print('batch_size, matrix_size, dtype'.ljust(35) + 'cpu_time(ms), gpu_time(ms)')\n",
    "    \n",
    "    shapes = itertools.product(\n",
    "        [[]] + [[2**x] for x in range(3)],\n",
    "        [2**i for i in range(1, 11)],\n",
    "        [torch.float]\n",
    "    )\n",
    "\n",
    "    with open(s+'.txt', 'w') as f:\n",
    "        for b, n, dtype in shapes:\n",
    "            if len(b) > 0 and b[0] * n >= 2**15:\n",
    "                continue\n",
    "            prof(b, n, dtype, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "1.7.0a0+4ae832e\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.011   7.446\n",
      "[] 4 torch.float32                  0.009   7.427\n",
      "[] 8 torch.float32                  0.011   7.571\n",
      "[] 16 torch.float32                 0.016   7.522\n",
      "[] 32 torch.float32                 0.033   7.548\n",
      "[] 64 torch.float32                 0.072   7.708\n",
      "[] 128 torch.float32                0.352   8.024\n",
      "[] 256 torch.float32                1.141   11.338\n",
      "[] 512 torch.float32                5.312   15.013\n",
      "[] 1024 torch.float32               19.364   19.271\n",
      "[1] 2 torch.float32                 0.009   0.114\n",
      "[1] 4 torch.float32                 0.009   0.117\n",
      "[1] 8 torch.float32                 0.011   0.126\n",
      "[1] 16 torch.float32                0.017   0.127\n",
      "[1] 32 torch.float32                0.033   0.178\n",
      "[1] 64 torch.float32                0.072   0.420\n",
      "[1] 128 torch.float32               0.294   0.801\n",
      "[1] 256 torch.float32               1.044   1.674\n",
      "[1] 512 torch.float32               4.726   4.791\n",
      "[1] 1024 torch.float32              16.592   16.266\n",
      "[2] 2 torch.float32                 0.010   0.114\n",
      "[2] 4 torch.float32                 0.010   0.120\n",
      "[2] 8 torch.float32                 0.013   0.119\n",
      "[2] 16 torch.float32                0.020   0.129\n",
      "[2] 32 torch.float32                0.050   0.174\n",
      "[2] 64 torch.float32                0.122   0.427\n",
      "[2] 128 torch.float32               0.553   0.914\n",
      "[2] 256 torch.float32               2.067   1.799\n",
      "[2] 512 torch.float32               9.127   4.506\n",
      "[2] 1024 torch.float32              32.653   18.171\n",
      "[4] 2 torch.float32                 0.010   0.115\n",
      "[4] 4 torch.float32                 0.010   0.118\n",
      "[4] 8 torch.float32                 0.014   0.118\n",
      "[4] 16 torch.float32                0.028   0.122\n",
      "[4] 32 torch.float32                0.086   0.175\n",
      "[4] 64 torch.float32                0.228   0.431\n",
      "[4] 128 torch.float32               1.065   0.932\n",
      "[4] 256 torch.float32               4.001   1.808\n",
      "[4] 512 torch.float32               18.434   4.896\n",
      "[4] 1024 torch.float32              59.073   19.991\n"
     ]
    }
   ],
   "source": [
    "main('before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n",
      "1.7.0a0+de440b5\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.022   0.168\n",
      "[] 4 torch.float32                  0.014   0.151\n",
      "[] 8 torch.float32                  0.016   0.152\n",
      "[] 16 torch.float32                 0.021   0.154\n",
      "[] 32 torch.float32                 0.040   0.204\n",
      "[] 64 torch.float32                 0.083   0.292\n",
      "[] 128 torch.float32                0.314   0.515\n",
      "[] 256 torch.float32                1.059   1.095\n",
      "[] 512 torch.float32                4.988   2.602\n",
      "[] 1024 torch.float32               17.429   7.000\n",
      "[1] 2 torch.float32                 0.009   0.142\n",
      "[1] 4 torch.float32                 0.009   0.142\n",
      "[1] 8 torch.float32                 0.011   0.140\n",
      "[1] 16 torch.float32                0.015   0.130\n",
      "[1] 32 torch.float32                0.032   0.173\n",
      "[1] 64 torch.float32                0.069   0.270\n",
      "[1] 128 torch.float32               0.387   0.492\n",
      "[1] 256 torch.float32               1.223   1.101\n",
      "[1] 512 torch.float32               4.422   2.607\n",
      "[1] 1024 torch.float32              15.060   6.999\n",
      "[2] 2 torch.float32                 0.009   0.193\n",
      "[2] 4 torch.float32                 0.011   0.190\n",
      "[2] 8 torch.float32                 0.012   0.200\n",
      "[2] 16 torch.float32                0.019   0.178\n",
      "[2] 32 torch.float32                0.051   0.246\n",
      "[2] 64 torch.float32                0.118   0.378\n",
      "[2] 128 torch.float32               0.566   0.685\n",
      "[2] 256 torch.float32               2.243   1.479\n",
      "[2] 512 torch.float32               8.956   3.537\n",
      "[2] 1024 torch.float32              30.416   12.496\n",
      "[4] 2 torch.float32                 0.010   0.321\n",
      "[4] 4 torch.float32                 0.010   0.320\n",
      "[4] 8 torch.float32                 0.014   0.321\n",
      "[4] 16 torch.float32                0.026   0.340\n",
      "[4] 32 torch.float32                0.084   0.378\n",
      "[4] 64 torch.float32                0.221   0.652\n",
      "[4] 128 torch.float32               1.057   1.062\n",
      "[4] 256 torch.float32               3.836   2.025\n",
      "[4] 512 torch.float32               17.304   5.074\n",
      "[4] 1024 torch.float32              60.581   19.830\n"
     ]
    }
   ],
   "source": [
    "main('after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape                      cpu_time, gpu_time_before (magma), gpu_time_after\n",
      "[] 2 torch.float32          0.016,  7.446,  0.168,      \n",
      "[] 4 torch.float32          0.012,  7.427,  0.150,      \n",
      "[] 8 torch.float32          0.013,  7.571,  0.152,      \n",
      "[] 16 torch.float32         0.018,  7.522,  0.154,      \n",
      "[] 32 torch.float32         0.036,  7.548,  0.204,      \n",
      "[] 64 torch.float32         0.078,  7.708,  0.292,      \n",
      "[] 128 torch.float32        0.333,  8.024,  0.515,      \n",
      "[] 256 torch.float32        1.100,  11.340,  1.095,      \n",
      "[] 512 torch.float32        5.150,  15.010,  2.602,      \n",
      "[] 1024 torch.float32       18.395,  19.270,  7.000,      \n",
      "[1] 2 torch.float32         0.009,  0.114,  0.142,           ******************** regressed\n",
      "[1] 4 torch.float32         0.009,  0.117,  0.142,           ******************** regressed\n",
      "[1] 8 torch.float32         0.011,  0.126,  0.140,           ******************** regressed\n",
      "[1] 16 torch.float32        0.016,  0.127,  0.130,           ******************** regressed\n",
      "[1] 32 torch.float32        0.032,  0.178,  0.173,      \n",
      "[1] 64 torch.float32        0.070,  0.420,  0.270,      \n",
      "[1] 128 torch.float32       0.341,  0.801,  0.492,      \n",
      "[1] 256 torch.float32       1.134,  1.674,  1.101,      \n",
      "[1] 512 torch.float32       4.574,  4.791,  2.607,      \n",
      "[1] 1024 torch.float32      15.825,  16.270,  6.999,      \n",
      "[2] 2 torch.float32         0.010,  0.114,  0.193,           ******************** regressed\n",
      "[2] 4 torch.float32         0.011,  0.120,  0.190,           ******************** regressed\n",
      "[2] 8 torch.float32         0.012,  0.118,  0.200,           ******************** regressed\n",
      "[2] 16 torch.float32        0.020,  0.129,  0.178,           ******************** regressed\n",
      "[2] 32 torch.float32        0.051,  0.173,  0.246,           ******************** regressed\n",
      "[2] 64 torch.float32        0.120,  0.427,  0.378,      \n",
      "[2] 128 torch.float32       0.560,  0.914,  0.685,      \n",
      "[2] 256 torch.float32       2.155,  1.799,  1.479,      \n",
      "[2] 512 torch.float32       9.041,  4.506,  3.537,      \n",
      "[2] 1024 torch.float32      31.535,  18.170,  12.500,      \n",
      "[4] 2 torch.float32         0.010,  0.115,  0.321,           ******************** regressed\n",
      "[4] 4 torch.float32         0.010,  0.118,  0.320,           ******************** regressed\n",
      "[4] 8 torch.float32         0.014,  0.118,  0.321,           ******************** regressed\n",
      "[4] 16 torch.float32        0.027,  0.122,  0.340,           ******************** regressed\n",
      "[4] 32 torch.float32        0.085,  0.175,  0.378,           ******************** regressed\n",
      "[4] 64 torch.float32        0.224,  0.431,  0.652,           ******************** regressed\n",
      "[4] 128 torch.float32       1.061,  0.932,  1.062,           ******************** regressed\n",
      "[4] 256 torch.float32       3.918,  1.808,  2.025,           ******************** regressed\n",
      "[4] 512 torch.float32       17.865,  4.896,  5.074,           ******************** regressed\n",
      "[4] 1024 torch.float32      59.825,  19.990,  19.830,      \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def readfile(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        fl = f.readlines()\n",
    "    \n",
    "    dc = {}\n",
    "    dg = {}\n",
    "    for _line in fl:\n",
    "        key, cpu_time, gpu_time = re.split(';|,', _line.rstrip())\n",
    "        dc[key] = float(cpu_time)\n",
    "        dg[key] = float(gpu_time)\n",
    "    \n",
    "    return (dc, dg)\n",
    "\n",
    "def compare(f, before: str, *afters):\n",
    "    assert len(afters) >= 1, 'provide at least one after data'\n",
    "\n",
    "    print('shape'.ljust(26), 'cpu_time, gpu_time_before (magma)', end='')\n",
    "    f.write('| shape | cpu_time (ms) | gpu_time_before (magma) (ms) |')\n",
    "    for after in afters:\n",
    "        print(', gpu_time_' + after.rstrip('.txt'), end='')\n",
    "        f.write(' gpu_time_' + after.rstrip('.txt') + ' (ms) |')\n",
    "    print()\n",
    "    f.write('\\n')\n",
    "    f.write('| --- ' * (len(afters) + 3) + '| \\n')\n",
    "\n",
    "    dc_b, dg_b = readfile(before)\n",
    "    dc_as = []\n",
    "    dg_as = []\n",
    "    for after in afters:\n",
    "        dc_a, dg_a = readfile(after)\n",
    "        dc_as.append(dc_a)\n",
    "        dg_as.append(dg_a)\n",
    "    \n",
    "    for key in dc_b:\n",
    "        cpu_time = (dc_b[key] + sum(dc_a[key] for dc_a in dc_as)) / (1 + len(dc_as))\n",
    "        gpu_time_before = dg_b[key]\n",
    "        gpu_time_after = dg_as[0][key]\n",
    "        \n",
    "        if gpu_time_after > gpu_time_before:\n",
    "            gs = ' ' * 5 + '*' * 20 + ' regressed'\n",
    "            gss = '***regressed'\n",
    "        else:\n",
    "            gs = ''\n",
    "            gss = ''\n",
    "\n",
    "        print(f'{key: <26} {cpu_time: .3f}, {gpu_time_before: .3f}, {gpu_time_after: .3f}, ' + ' '*5, end='')\n",
    "        f.write(f'| {key} | {cpu_time: .3f} | {gpu_time_before: .3f} | {gpu_time_after: .3f} {gss} | ')\n",
    "        for dg_a in dg_as[1:]:\n",
    "            gpu_time_after = dg_a[key]\n",
    "            print(f'{gpu_time_after: .3f}, ', end='')\n",
    "            f.write(f'{gpu_time_after: .3f} |')\n",
    "        print(gs)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('table.md', 'w') as f:\n",
    "    compare(f, 'before.txt', 'after.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitfce950e88ea94256bae6c6f663f53e68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
