{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: GeForce RTX 2070 SUPER \r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi -L | cut -d '(' -f 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import itertools\n",
    "\n",
    "nb = 500\n",
    "\n",
    "def main(s: str):\n",
    "    def prof(b_, n_, dtype, f):\n",
    "        # print(b_, n_)\n",
    "        x = torch.randn(*b_, n_, n_, device='cuda', dtype=dtype)\n",
    "\n",
    "        xc = x.clone().cpu()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            yc = torch.inverse(xc)\n",
    "        t2 = time.time()\n",
    "        cpu_time = (t2-t1)/nb*1e3\n",
    "        # print('cpu', cpu_time, 'ms')\n",
    "\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        c, d = torch.testing._compare_tensors_internal(xc.cuda(), x, rtol=1e-7, atol=1e-7, equal_nan=False)\n",
    "        if not c:\n",
    "            print('original matrix compare')\n",
    "            print(d)\n",
    "            raise RuntimeError('original value modified')\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        t1 = time.time()\n",
    "        for _ in range(nb):\n",
    "            y = torch.inverse(x)\n",
    "        torch.cuda.synchronize()\n",
    "        t2 = time.time()\n",
    "        gpu_time = (t2-t1)/nb*1e3\n",
    "        # print('gpu', gpu_time, 'ms')\n",
    "\n",
    "        a, b = torch.testing._compare_tensors_internal(yc.cuda(), y, rtol=1e-3, atol=1e-3, equal_nan=False)\n",
    "        if not a:\n",
    "            print('numerical mismatch: inverse value compare')\n",
    "            print(b)\n",
    "\n",
    "        print(f'{b_} {n_} {dtype}'.ljust(35) + f'{cpu_time : .3f}  {gpu_time : .3f}')\n",
    "        f.write(f'{b_} {n_} {dtype}; ' + f'{cpu_time : .3e}, {gpu_time : .3e}\\n')\n",
    "        torch.cuda.synchronize()\n",
    "    \n",
    "    print(s)\n",
    "    print(torch.__version__)\n",
    "    print()\n",
    "    print('batch_size, matrix_size, dtype'.ljust(35) + 'cpu_time(ms), gpu_time(ms)')\n",
    "    \n",
    "    shapes = itertools.product(\n",
    "        [[]] + [[2**x] for x in range(3)],\n",
    "        [2**i for i in range(1, 11)],\n",
    "        [torch.float]\n",
    "    )\n",
    "\n",
    "    with open(s+'.txt', 'w') as f:\n",
    "        for b, n, dtype in shapes:\n",
    "            if len(b) > 0 and b[0] * n >= 2**15:\n",
    "                continue\n",
    "            prof(b, n, dtype, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n",
      "1.7.0a0+28bd492\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.084   7.534\n",
      "[] 4 torch.float32                  0.009   7.522\n",
      "[] 8 torch.float32                  0.011   7.647\n",
      "[] 16 torch.float32                 0.063   7.582\n",
      "[] 32 torch.float32                 0.065   7.573\n",
      "[] 64 torch.float32                 0.151   7.694\n",
      "[] 128 torch.float32                0.414   8.073\n",
      "[] 256 torch.float32                1.121   11.864\n",
      "[] 512 torch.float32                5.250   14.132\n",
      "[] 1024 torch.float32               18.752   18.784\n",
      "[1] 2 torch.float32                 0.009   0.113\n",
      "[1] 4 torch.float32                 0.009   0.113\n",
      "[1] 8 torch.float32                 0.011   0.116\n",
      "[1] 16 torch.float32                0.015   0.122\n",
      "[1] 32 torch.float32                0.032   0.177\n",
      "[1] 64 torch.float32                0.071   0.420\n",
      "[1] 128 torch.float32               0.306   0.816\n",
      "[1] 256 torch.float32               1.118   1.690\n",
      "[1] 512 torch.float32               4.662   4.305\n",
      "[1] 1024 torch.float32              16.436   16.336\n",
      "[2] 2 torch.float32                 0.009   0.113\n",
      "[2] 4 torch.float32                 0.009   0.115\n",
      "[2] 8 torch.float32                 0.012   0.114\n",
      "[2] 16 torch.float32                0.019   0.119\n",
      "[2] 32 torch.float32                0.051   0.170\n",
      "[2] 64 torch.float32                0.122   0.429\n",
      "[2] 128 torch.float32               0.598   0.830\n",
      "[2] 256 torch.float32               2.030   1.748\n",
      "[2] 512 torch.float32               8.950   4.749\n",
      "[2] 1024 torch.float32              33.637   18.235\n",
      "[4] 2 torch.float32                 0.009   0.112\n",
      "[4] 4 torch.float32                 0.010   0.115\n",
      "[4] 8 torch.float32                 0.014   0.115\n",
      "[4] 16 torch.float32                0.028   0.120\n",
      "[4] 32 torch.float32                0.085   0.173\n",
      "[4] 64 torch.float32                0.220   0.431\n",
      "[4] 128 torch.float32               1.215   0.834\n",
      "[4] 256 torch.float32               4.033   1.811\n",
      "[4] 512 torch.float32               17.902   4.884\n",
      "[4] 1024 torch.float32              68.532   19.836\n"
     ]
    }
   ],
   "source": [
    "main('before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after\n",
      "1.7.0a0+73499c6\n",
      "\n",
      "batch_size, matrix_size, dtype     cpu_time(ms), gpu_time(ms)\n",
      "[] 2 torch.float32                  0.105   0.129\n",
      "[] 4 torch.float32                  0.009   0.129\n",
      "[] 8 torch.float32                  0.011   0.138\n",
      "[] 16 torch.float32                 0.088   0.134\n",
      "[] 32 torch.float32                 0.081   0.191\n",
      "[] 64 torch.float32                 0.116   0.288\n",
      "[] 128 torch.float32                0.383   0.491\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 65524 element(s) (out of 65536) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 268.33642578125 (3061.600830078125 vs. 3329.937255859375), which occurred at index (4, 154).\n",
      "[] 256 torch.float32                0.987   1.074\n",
      "[] 512 torch.float32                5.186   2.582\n",
      "[] 1024 torch.float32               19.275   6.936\n",
      "[1] 2 torch.float32                 0.009   0.128\n",
      "[1] 4 torch.float32                 0.008   0.131\n",
      "[1] 8 torch.float32                 0.011   0.129\n",
      "[1] 16 torch.float32                0.015   0.134\n",
      "[1] 32 torch.float32                0.031   0.178\n",
      "[1] 64 torch.float32                0.069   0.281\n",
      "[1] 128 torch.float32               0.350   0.490\n",
      "[1] 256 torch.float32               1.131   1.084\n",
      "[1] 512 torch.float32               4.025   2.576\n",
      "[1] 1024 torch.float32              16.581   6.928\n",
      "[2] 2 torch.float32                 0.009   0.186\n",
      "[2] 4 torch.float32                 0.012   0.184\n",
      "[2] 8 torch.float32                 0.012   0.184\n",
      "[2] 16 torch.float32                0.020   0.174\n",
      "[2] 32 torch.float32                0.049   0.240\n",
      "[2] 64 torch.float32                0.119   0.375\n",
      "[2] 128 torch.float32               0.553   0.675\n",
      "[2] 256 torch.float32               2.011   1.451\n",
      "[2] 512 torch.float32               9.190   3.539\n",
      "[2] 1024 torch.float32              33.670   12.217\n",
      "[4] 2 torch.float32                 0.009   0.318\n",
      "[4] 4 torch.float32                 0.009   0.319\n",
      "[4] 8 torch.float32                 0.013   0.319\n",
      "[4] 16 torch.float32                0.027   0.331\n",
      "[4] 32 torch.float32                0.084   0.385\n",
      "[4] 64 torch.float32                0.222   0.646\n",
      "[4] 128 torch.float32               0.990   1.055\n",
      "[4] 256 torch.float32               4.050   2.054\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 27443 element(s) (out of 1048576) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.01809406280517578 (-12.35366439819336 vs. -12.371758460998535), which occurred at index (0, 338, 417).\n",
      "[4] 512 torch.float32               18.882   5.087\n",
      "numerical mismatch: inverse value compare\n",
      "With rtol=0.001 and atol=0.001, found 143856 element(s) (out of 4194304) whose difference(s) exceeded the margin of error (including 0 nan comparisons). The greatest difference was 0.02208232879638672 (11.406448364257812 vs. 11.384366035461426), which occurred at index (1, 918, 132).\n",
      "[4] 1024 torch.float32              69.523   19.995\n"
     ]
    }
   ],
   "source": [
    "main('after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape                      cpu_time, gpu_time_before (magma), gpu_time_after\n",
      "[] 2 torch.float32          0.095,  7.534,  0.129,      \n",
      "[] 4 torch.float32          0.009,  7.522,  0.129,      \n",
      "[] 8 torch.float32          0.011,  7.647,  0.138,      \n",
      "[] 16 torch.float32         0.075,  7.582,  0.135,      \n",
      "[] 32 torch.float32         0.073,  7.573,  0.191,      \n",
      "[] 64 torch.float32         0.134,  7.694,  0.288,      \n",
      "[] 128 torch.float32        0.398,  8.073,  0.491,      \n",
      "[] 256 torch.float32        1.054,  11.860,  1.074,      \n",
      "[] 512 torch.float32        5.218,  14.130,  2.582,      \n",
      "[] 1024 torch.float32       19.010,  18.780,  6.936,      \n",
      "[1] 2 torch.float32         0.009,  0.113,  0.128,           ******************** regressed\n",
      "[1] 4 torch.float32         0.009,  0.113,  0.131,           ******************** regressed\n",
      "[1] 8 torch.float32         0.011,  0.116,  0.129,           ******************** regressed\n",
      "[1] 16 torch.float32        0.015,  0.122,  0.135,           ******************** regressed\n",
      "[1] 32 torch.float32        0.032,  0.177,  0.178,           ******************** regressed\n",
      "[1] 64 torch.float32        0.070,  0.420,  0.281,      \n",
      "[1] 128 torch.float32       0.328,  0.816,  0.490,      \n",
      "[1] 256 torch.float32       1.125,  1.690,  1.084,      \n",
      "[1] 512 torch.float32       4.344,  4.305,  2.576,      \n",
      "[1] 1024 torch.float32      16.510,  16.340,  6.928,      \n",
      "[2] 2 torch.float32         0.009,  0.113,  0.186,           ******************** regressed\n",
      "[2] 4 torch.float32         0.011,  0.115,  0.184,           ******************** regressed\n",
      "[2] 8 torch.float32         0.012,  0.114,  0.184,           ******************** regressed\n",
      "[2] 16 torch.float32        0.019,  0.119,  0.173,           ******************** regressed\n",
      "[2] 32 torch.float32        0.050,  0.170,  0.240,           ******************** regressed\n",
      "[2] 64 torch.float32        0.120,  0.429,  0.375,      \n",
      "[2] 128 torch.float32       0.576,  0.830,  0.675,      \n",
      "[2] 256 torch.float32       2.021,  1.748,  1.451,      \n",
      "[2] 512 torch.float32       9.070,  4.749,  3.539,      \n",
      "[2] 1024 torch.float32      33.655,  18.240,  12.220,      \n",
      "[4] 2 torch.float32         0.009,  0.112,  0.318,           ******************** regressed\n",
      "[4] 4 torch.float32         0.010,  0.115,  0.319,           ******************** regressed\n",
      "[4] 8 torch.float32         0.013,  0.115,  0.320,           ******************** regressed\n",
      "[4] 16 torch.float32        0.027,  0.120,  0.331,           ******************** regressed\n",
      "[4] 32 torch.float32        0.085,  0.173,  0.385,           ******************** regressed\n",
      "[4] 64 torch.float32        0.221,  0.431,  0.646,           ******************** regressed\n",
      "[4] 128 torch.float32       1.102,  0.834,  1.055,           ******************** regressed\n",
      "[4] 256 torch.float32       4.042,  1.811,  2.054,           ******************** regressed\n",
      "[4] 512 torch.float32       18.390,  4.884,  5.087,           ******************** regressed\n",
      "[4] 1024 torch.float32      69.025,  19.840,  20.000,           ******************** regressed\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def readfile(fn):\n",
    "    with open(fn, 'r') as f:\n",
    "        fl = f.readlines()\n",
    "    \n",
    "    dc = {}\n",
    "    dg = {}\n",
    "    for _line in fl:\n",
    "        key, cpu_time, gpu_time = re.split(';|,', _line.rstrip())\n",
    "        dc[key] = float(cpu_time)\n",
    "        dg[key] = float(gpu_time)\n",
    "    \n",
    "    return (dc, dg)\n",
    "\n",
    "def compare(f, before: str, *afters):\n",
    "    assert len(afters) >= 1, 'provide at least one after data'\n",
    "\n",
    "    print('shape'.ljust(26), 'cpu_time, gpu_time_before (magma)', end='')\n",
    "    f.write('| shape | cpu_time (ms) | gpu_time_before (magma) (ms) |')\n",
    "    for after in afters:\n",
    "        print(', gpu_time_' + after.rstrip('.txt'), end='')\n",
    "        f.write(' gpu_time_' + after.rstrip('.txt') + ' (ms) |')\n",
    "    print()\n",
    "    f.write('\\n')\n",
    "    f.write('| --- ' * (len(afters) + 3) + '| \\n')\n",
    "\n",
    "    dc_b, dg_b = readfile(before)\n",
    "    dc_as = []\n",
    "    dg_as = []\n",
    "    for after in afters:\n",
    "        dc_a, dg_a = readfile(after)\n",
    "        dc_as.append(dc_a)\n",
    "        dg_as.append(dg_a)\n",
    "    \n",
    "    for key in dc_b:\n",
    "        cpu_time = (dc_b[key] + sum(dc_a[key] for dc_a in dc_as)) / (1 + len(dc_as))\n",
    "        gpu_time_before = dg_b[key]\n",
    "        gpu_time_after = dg_as[0][key]\n",
    "        \n",
    "        if gpu_time_after > gpu_time_before:\n",
    "            gs = ' ' * 5 + '*' * 20 + ' regressed'\n",
    "            gss = '***regressed'\n",
    "        else:\n",
    "            gs = ''\n",
    "            gss = ''\n",
    "\n",
    "        print(f'{key: <26} {cpu_time: .3f}, {gpu_time_before: .3f}, {gpu_time_after: .3f}, ' + ' '*5, end='')\n",
    "        f.write(f'| {key} | {cpu_time: .3f} | {gpu_time_before: .3f} | {gpu_time_after: .3f} {gss} | ')\n",
    "        for dg_a in dg_as[1:]:\n",
    "            gpu_time_after = dg_a[key]\n",
    "            print(f'{gpu_time_after: .3f}, ', end='')\n",
    "            f.write(f'{gpu_time_after: .3f} |')\n",
    "        print(gs)\n",
    "        f.write('\\n')\n",
    "\n",
    "with open('table.md', 'w') as f:\n",
    "    compare(f, 'before.txt', 'after.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitfce950e88ea94256bae6c6f663f53e68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
