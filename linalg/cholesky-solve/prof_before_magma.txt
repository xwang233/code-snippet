
1.9.0a0+git80a4a50

batch_size, matrix_size, dtype     cpu_time(us), gpu_time(us)
[] 2 torch.float32                  12.269   520.470
[] 4 torch.float32                  12.559   504.800
[] 8 torch.float32                  12.847   510.757
[] 16 torch.float32                 13.968   502.247
[] 32 torch.float32                 16.428   500.348
[] 64 torch.float32                 68.655   513.765
[] 128 torch.float32                124.538   547.231
[] 256 torch.float32                340.979   667.753
[] 512 torch.float32                1149.302   891.056
[] 1024 torch.float32               6145.139   1832.751
[] 2048 torch.float32               40228.230   5711.654
[1] 2 torch.float32                 12.803   46.219
[1] 4 torch.float32                 12.921   46.805
[1] 8 torch.float32                 13.111   49.460
[1] 16 torch.float32                14.056   47.026
[1] 32 torch.float32                16.868   102.577
[1] 64 torch.float32                56.237   155.920
[1] 128 torch.float32               106.741   270.469
[1] 256 torch.float32               309.737   510.722
[1] 512 torch.float32               822.852   1045.516
[1] 1024 torch.float32              4281.462   2550.684
[1] 2048 torch.float32              26400.250   7961.073
[2] 2 torch.float32                 13.753   46.866
[2] 4 torch.float32                 10.635   48.810
[2] 8 torch.float32                 10.540   49.063
[2] 16 torch.float32                11.692   48.621
[2] 32 torch.float32                17.431   109.123
[2] 64 torch.float32                146.792   170.259
[2] 128 torch.float32               226.016   342.236
[2] 256 torch.float32               455.259   561.134
[2] 512 torch.float32               1448.921   1203.861
[2] 1024 torch.float32              9051.031   3261.784
[2] 2048 torch.float32              60518.496   12410.305
[4] 2 torch.float32                 12.248   47.059
[4] 4 torch.float32                 13.069   47.290
[4] 8 torch.float32                 13.021   47.865
[4] 16 torch.float32                16.097   48.300
[4] 32 torch.float32                27.065   105.646
[4] 64 torch.float32                179.584   163.871
[4] 128 torch.float32               343.558   292.679
[4] 256 torch.float32               567.468   587.190
[4] 512 torch.float32               2647.763   1411.860
[4] 1024 torch.float32              17503.778   4578.091
[4] 2048 torch.float32              120014.284   20792.960
[8] 2 torch.float32                 14.577   46.604
[8] 4 torch.float32                 16.508   47.126
[8] 8 torch.float32                 16.360   46.688
[8] 16 torch.float32                21.337   46.530
[8] 32 torch.float32                43.187   103.214
[8] 64 torch.float32                330.442   163.722
[8] 128 torch.float32               440.171   306.680
[8] 256 torch.float32               1115.618   680.860
[8] 512 torch.float32               4982.163   1925.489
[8] 1024 torch.float32              42052.629   7305.988
[16] 2 torch.float32                22.047   47.334
[16] 4 torch.float32                24.865   46.957
[16] 8 torch.float32                25.846   46.803
[16] 16 torch.float32               34.480   47.257
[16] 32 torch.float32               78.174   108.027
[16] 64 torch.float32               556.331   176.191
[16] 128 torch.float32              744.597   337.745
[16] 256 torch.float32              1916.068   872.037
[16] 512 torch.float32              11305.681   2895.424
[32] 2 torch.float32                32.164   46.477
[32] 4 torch.float32                36.606   47.406
[32] 8 torch.float32                37.344   47.215
[32] 16 torch.float32               56.531   47.371
[32] 32 torch.float32               144.533   109.394
[32] 64 torch.float32               936.669   183.723
[32] 128 torch.float32              1347.916   414.745
[32] 256 torch.float32              3857.687   1249.048
[64] 2 torch.float32                51.146   47.251
[64] 4 torch.float32                60.283   47.361
[64] 8 torch.float32                61.777   48.034
[64] 16 torch.float32               99.616   47.563
[64] 32 torch.float32               382.966   113.740
[64] 64 torch.float32               1633.712   206.974
[64] 128 torch.float32              2593.771   553.219
[128] 2 torch.float32               87.448   47.740
[128] 4 torch.float32               107.031   47.644
[128] 8 torch.float32               109.878   48.805
[128] 16 torch.float32              188.185   49.096
[128] 32 torch.float32              692.812   120.820
[128] 64 torch.float32              3074.011   256.456
[256] 2 torch.float32               162.712   49.546
[256] 4 torch.float32               202.166   49.155
[256] 8 torch.float32               207.558   50.060
[256] 16 torch.float32              549.916   52.416
[256] 32 torch.float32              1274.049   140.007
[512] 2 torch.float32               311.476   52.310
[512] 4 torch.float32               391.147   52.406
[512] 8 torch.float32               403.419   54.011
[512] 16 torch.float32              1001.960   60.629
[1024] 2 torch.float32              646.455   62.464
[1024] 4 torch.float32              767.053   62.680
[1024] 8 torch.float32              1409.421   69.155
