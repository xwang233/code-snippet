{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.testing import _compare_tensors_internal\n",
    "\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "\n",
    "def p(device, dtype, msg):\n",
    "    def topKViaSort(x, k, dim):\n",
    "        val, idx = x.sort(dim, True)\n",
    "        return (val.narrow(dim, 0, k), idx.narrow(dim, 0, k))\n",
    "    def run(func, reps=200):\n",
    "        # warmup\n",
    "        for _ in range(reps):\n",
    "            func()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        start_t = time.time()\n",
    "        \n",
    "        for _ in range(reps):\n",
    "            y = func()\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        end_t = time.time()\n",
    "        \n",
    "        return (end_t - start_t) / reps\n",
    "    \n",
    "    print(torch.__version__)\n",
    "    print('device:', device)\n",
    "    \n",
    "    ns = [1, 3, 10]\n",
    "    bs = [int(1e4), int(5e4), int(1e5), int(5e5), int(1e6), int(5e6), int(1e7), int(5e7), int(1e8)] \\\n",
    "        + torch.randint(int(1e5), int(1e7), (50, )).tolist()\n",
    "    ks = [1, 10, 50, 100, 500, 1000]\n",
    "    \n",
    "    sizes = []\n",
    "    for n1 in ns:\n",
    "        for n2 in ns:\n",
    "            for b in bs:\n",
    "                for k in ks:\n",
    "                    sizes.append((n1, n2, b, k, -1))\n",
    "                    sizes.append((n1, b, n2, k, 1))\n",
    "                    sizes.append((b, n1, n2, k, 0))\n",
    "    fn = f'{msg}-{device}-{dtype}.txt'\n",
    "    print(fn)\n",
    "    print(f'total {len(sizes)} sizes\\n')\n",
    "    \n",
    "    t1 = time.time()\n",
    "\n",
    "    with open(fn, 'w') as f:\n",
    "        for size in sizes:\n",
    "            try:\n",
    "                torch.cuda.empty_cache()\n",
    "                x = torch.randn(*size[:-2], device=device, dtype=dtype)\n",
    "\n",
    "                t = run(lambda: torch.topk(x, k=size[-2], dim=size[-1]))\n",
    "                t *= 1000\n",
    "                f.write(f'{size} # {t}\\n')\n",
    "\n",
    "                y1 = torch.topk(x, k=size[-2], dim=size[-1])\n",
    "                y2 = topKViaSort(x, k=size[-2], dim=size[-1])\n",
    "\n",
    "                # values should be exactly equal\n",
    "                a, b = _compare_tensors_internal(y1.values, y2[0], atol=0, rtol=0, equal_nan=False)\n",
    "                assert a, b\n",
    "\n",
    "\n",
    "                if not y1.indices.eq(y2[1]).all():\n",
    "                    vals = x.gather(index=y1.indices, dim=size[-1])\n",
    "                    a, b = _compare_tensors_internal(vals, y2[0], atol=0, rtol=0, equal_nan=False)\n",
    "                    assert a, b\n",
    "                    \n",
    "            except RuntimeError as e:\n",
    "                if str(e).startswith('CUDA out of memory'):\n",
    "                    print(f'{size} OOM')\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise        \n",
    "                \n",
    "    t2 = time.time()\n",
    "    print(f'total time {t2 - t1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "p('cuda', torch.float, 'before')\n",
    "p('cuda', torch.half, 'before')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p('cuda', torch.float, 'after')\n",
    "p('cuda', torch.half, 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def compare(name: str):\n",
    "    def parse(_name: str):\n",
    "        with open(_name, 'r') as f:\n",
    "            ln = f.readlines()\n",
    "            \n",
    "        d = {}\n",
    "        for line in ln:\n",
    "            idx = line.index('#')\n",
    "            key = line[:idx]\n",
    "            val = float(line[idx+1:])\n",
    "            \n",
    "            d[key] = val\n",
    "        \n",
    "        return d\n",
    "    \n",
    "    print(name)\n",
    "    before_name = 'before-' + name\n",
    "    after_name = 'after-' + name\n",
    "    \n",
    "    d_before = parse(before_name)\n",
    "    d_after = parse(after_name)\n",
    "    diff = []\n",
    "    \n",
    "    for key in d_before:\n",
    "        assert key in d_after\n",
    "        \n",
    "        tb = d_before[key]\n",
    "        ta = d_after[key]\n",
    "        \n",
    "        diff.append((ta-tb)/tb)\n",
    "    \n",
    "    sns.distplot(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda-torch.float32.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xwang/.local/lib/python3.7/site-packages/seaborn/distributions.py:288: UserWarning: Data must have variance to compute a kernel density estimate.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare('cuda-torch.float32.txt')\n",
    "# compare('cuda-torch.float16.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bitfce950e88ea94256bae6c6f663f53e68"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
