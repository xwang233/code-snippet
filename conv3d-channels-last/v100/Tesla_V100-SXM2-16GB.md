
## profiling

device is Tesla V100-SXM2-16GB

cudnn_ver is 8005

time is in ms

backward is dgrad + wgrad

shape is (n, c, dhw, oc, ks, pad, stride)

E.g. (2, 4, 128, 32, 3, 1, 1) means

```python
x = torch.randn(2, 4, 128, 128, 128, dtype=torch.half, device='cuda').requires_grad_()
x = x.to(memory_format=torch.channels_last_3d)
net = torch.nn.Conv3d(4, 32, kernel_size=3, padding=1, stride=1)
net = net.to(dtype=torch.half, device='cuda', memory_format=torch.channels_last_3d)
net(x)
```

### channels-last-3d-forward

| shape | contiguous | master (ch-last) | PR (ch-last) | PR > master (ch-last)? | PR > contiguous? |
| --- | --- | --- | --- | --- | --- |
| (2, 1024, 8, 512, 3, 1, 1)| 0.645 | 0.664 | 0.568 | 1.17x | 1.13x |
| (2, 128, 32, 128, 3, 1, 1)| 1.036 | 1.208 | 0.921 | 1.31x | 1.11x |
| (2, 128, 32, 256, 2, 0, 2)| 0.147 | 0.318 | 0.108 | 2.94x | 1.36x |
| (2, 128, 32, 256, 3, 1, 2)| 0.267 | 0.433 | 0.200 | 2.17x | 1.32x |
| (2, 128, 64, 64, 3, 1, 1)| 4.098 | 14.220 | 3.472 | 4.10x | 1.18x |
| (2, 256, 16, 256, 3, 1, 1)| 0.413 | 0.447 | 0.382 | 1.17x | 1.07x |
| (2, 256, 16, 512, 2, 0, 2)| 0.130 | 0.175 | 0.116 | 1.51x | 1.37x |
| (2, 256, 16, 512, 3, 1, 2)| 0.196 | 0.230 | 0.158 | 1.46x | 1.24x |
| (2, 256, 32, 128, 3, 1, 1)| 1.773 | 2.092 | 1.602 | 1.31x | 1.10x |
| (2, 32, 128, 32, 3, 1, 1)| 8.575 | 19.002 | 6.957 | 2.73x | 1.22x |
| (2, 32, 128, 4, 1, 0, 1)| 1.735 | 12.565 | 1.164 | 10.80x | 1.49x |
| (2, 32, 128, 64, 2, 0, 2)| 1.855 | 12.638 | 0.800 | 15.79x | 2.31x |
| (2, 32, 128, 64, 3, 1, 2)| 2.409 | 13.247 | 1.414 | 9.37x | 1.73x |
| (2, 4, 128, 32, 3, 1, 1)| 5.542 | 5.720 | 5.381 | 1.06x | 1.03x |
| (2, 512, 16, 256, 3, 1, 1)| 0.793 | 0.856 | 0.740 | 1.16x | 1.06x |
| (2, 512, 4, 512, 3, 1, 1)| 0.127 | 0.147 | 0.113 | 1.30x | 1.13x |
| (2, 512, 8, 512, 2, 0, 2)| 0.128 | 0.173 | 0.113 | 1.53x | 1.31x |
| (2, 512, 8, 512, 3, 1, 1)| 0.349 | 0.363 | 0.306 | 1.19x | 1.14x |
| (2, 512, 8, 512, 3, 1, 2)| 0.130 | 0.177 | 0.116 | 1.53x | 1.29x |
| (2, 64, 128, 32, 3, 1, 1)| 11.898 | 53.034 | 9.681 | 5.48x | 1.22x |
| (2, 64, 64, 128, 2, 0, 2)| 0.528 | 5.702 | 0.275 | 20.76x | 1.93x |
| (2, 64, 64, 128, 3, 1, 2)| 0.729 | 5.866 | 0.483 | 12.14x | 1.51x |
| (2, 64, 64, 64, 3, 1, 1)| 2.371 | 7.406 | 1.938 | 3.82x | 1.22x |



### channels-last-3d-backward

| shape | contiguous | master (ch-last) | PR (ch-last) | PR > master (ch-last)? | PR > contiguous? |
| --- | --- | --- | --- | --- | --- |
| (2, 1024, 8, 512, 3, 1, 1)| 1.247 | 1.293 | 1.065 | 1.21x | 1.16x |
| (2, 128, 32, 128, 3, 1, 1)| 2.019 | 2.268 | 1.849 | 1.23x | 1.08x |
| (2, 128, 32, 256, 2, 0, 2)| 0.491 | 0.582 | 0.355 | 1.64x | 1.39x |
| (2, 128, 32, 256, 3, 1, 2)| 0.782 | 0.863 | 0.648 | 1.33x | 1.23x |
| (2, 128, 64, 64, 3, 1, 1)| 9.245 | 15.671 | 8.175 | 1.92x | 1.13x |
| (2, 256, 16, 256, 3, 1, 1)| 0.939 | 1.010 | 0.868 | 1.16x | 1.08x |
| (2, 256, 16, 512, 2, 0, 2)| 0.242 | 0.319 | 0.239 | 1.33x | 1.04x |
| (2, 256, 16, 512, 3, 1, 2)| 0.521 | 0.563 | 0.443 | 1.27x | 1.17x |
| (2, 256, 32, 128, 3, 1, 1)| 3.491 | 3.830 | 3.261 | 1.17x | 1.07x |
| (2, 32, 128, 32, 3, 1, 1)| 19.555 | 30.190 | 16.683 | 1.81x | 1.17x |
| (2, 32, 128, 4, 1, 0, 1)| 4.210 | 5.064 | 2.948 | 1.72x | 1.43x |
| (2, 32, 128, 64, 2, 0, 2)| 5.449 | 11.265 | 4.605 | 2.45x | 1.18x |
| (2, 32, 128, 64, 3, 1, 2)| 8.173 | 13.988 | 6.464 | 2.16x | 1.27x |
| (2, 4, 128, 32, 3, 1, 1)| 16.754 | 27.446 | 14.830 | 1.85x | 1.13x |
| (2, 512, 16, 256, 3, 1, 1)| 1.778 | 1.847 | 1.661 | 1.11x | 1.06x |
| (2, 512, 4, 512, 3, 1, 1)| 0.271 | 0.289 | 0.216 | 1.34x | 1.24x |
| (2, 512, 8, 512, 2, 0, 2)| 0.231 | 0.287 | 0.232 | 1.23x | 1.09x |
| (2, 512, 8, 512, 3, 1, 1)| 0.673 | 0.701 | 0.572 | 1.22x | 1.19x |
| (2, 512, 8, 512, 3, 1, 2)| 0.309 | 0.346 | 0.210 | 1.65x | 1.46x |
| (2, 64, 128, 32, 3, 1, 1)| 35.245 | 49.450 | 30.389 | 1.63x | 1.16x |
| (2, 64, 64, 128, 2, 0, 2)| 1.893 | 2.436 | 1.412 | 1.72x | 1.34x |
| (2, 64, 64, 128, 3, 1, 2)| 2.363 | 2.878 | 1.914 | 1.50x | 1.24x |
| (2, 64, 64, 64, 3, 1, 1)| 5.343 | 10.527 | 4.620 | 2.28x | 1.16x |



